import streamlit as st
from playwright.sync_api import sync_playwright
from datetime import datetime, timedelta, time as dt_time
import threading
import json
import time
import os
import re
from dotenv import load_dotenv

# ==========================================
# 1. çˆ¬èŸ²æ©Ÿå™¨äººåŠŸèƒ½å€å¡Š
# ==========================================
def extract_total_count(text):
    if not text: return "0"
    numbers = re.findall(r'\d+', text)
    return numbers[-1] if numbers else "0"

def scrape_single_date(page, date_str):
    base_url = (
        f"https://merchant.shoalter.com/zh/order-management/orders/toship"
        f"?bu=HKTV&deliveryType=STANDARD_DELIVERY&productReadyMethod=STANDARD_DELIVERY_ALL"
        f"&searchType=ORDER_ID&storefrontCodes=H0956004%2CH0956006%2CH0956007%2CH0956008%2CH0956010%2CH0956012"
        f"&dateType=PICK_UP_DATE&startDate={date_str}&endDate={date_str}"
        f"&pageSize=20&pageNumber=1&sortColumn=orderDate&waybillStatuses="
    )
    statuses = [("CONFIRMED", "å·²å»ºç«‹"), ("ACKNOWLEDGED", "å·²ç¢ºèª"), ("PACKED", "å·²åŒ…è£"), ("PICKED", "å·²å‡ºè²¨")]
    date_data = {"date": date_str}

    # 1. é€²å…¥ç•¶å¤©çš„åˆå§‹é é¢ (é¡¯ç¤ºç¸½æ•¸)
    page.goto(base_url)
    page.wait_for_timeout(5000) # çµ¦ç¶²é å……åˆ†çš„æ™‚é–“åˆå§‹åŒ–

    # 2. é»æ“Šã€Œå•†æˆ¶8å°æ™‚é€è²¨ã€
    try:
        page.locator('button:has-text("å•†æˆ¶8å°æ™‚é€è²¨")').click(timeout=3000, force=True)
        page.wait_for_timeout(3000)
    except Exception:
        pass

    # 3. è®“æ©Ÿå™¨äººä¹–ä¹–æ‰“é–‹é¸å–®ï¼Œä¸€å€‹ä¸€å€‹å‹¾é¸
    for status_val, status_name in statuses:
        try:
            # å±•é–‹ã€Œé‹å–®ç‹€æ…‹ã€é¸å–®
            page.locator('div.ant-select-selector:has-text("é‹å–®ç‹€æ…‹")').click(force=True)
            page.wait_for_timeout(1500) # ç­‰å¾…é¸å–®å‹•ç•«å±•é–‹

            # é»æ“Šã€Œæ¸…é™¤å…¨éƒ¨ã€ç¢ºä¿ä¸æœƒç–ŠåŠ 
            page.locator('button[data-testid="æ¸…é™¤å…¨éƒ¨"]').click(force=True)
            page.wait_for_timeout(1000)

            # å¼·åˆ¶å‹¾é¸ç›®æ¨™ç‹€æ…‹
            checkbox = page.locator(f'input[value="{status_val}"]')
            checkbox.click(force=True)
            page.wait_for_timeout(1000)

            # é»æ“Šã€Œå¥—ç”¨ã€
            page.locator('button[data-testid="å¥—ç”¨"]').click(force=True)

            # ğŸ›‘ æ ¸å¿ƒé—œéµï¼šå¼·åˆ¶ç­‰å¾… 6 ç§’ï¼
            # è®“ç¶²é æœ‰è¶³å¤ çš„æ™‚é–“å¾ç¸½æ•¸ (ä¾‹å¦‚ 18) åˆ·æ–°ç‚ºå¯¦éš›éæ¿¾å¾Œçš„æ•¸å­—ï¼
            page.wait_for_timeout(6000)

            # æŠ“å–åˆ·æ–°å¾Œçš„æ–‡å­—
            result_text = page.locator('span:has-text("çµæœ")').last.inner_text(timeout=5000)
            date_data[status_val] = extract_total_count(result_text)

        except Exception as e:
            print(f"æŠ“å– {status_name} å¤±æ•—: {e}")
            date_data[status_val] = "0"
            
    return date_data

def scrape_hktvmall(username, password):
    now = datetime.utcnow() + timedelta(hours=8)
    
    today_str = now.strftime("%Y-%m-%d")
    tomorrow_str = (now + timedelta(days=1)).strftime("%Y-%m-%d")
    
    file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'order_data.json')
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            results_data = json.load(f)
    except Exception:
        results_data = {"today": {}, "tomorrow": {}}

    results_data["status_msg"] = "âš¡ æ©Ÿå™¨äººé‹è¡Œä¸­ï¼šæ¯ 3 åˆ†é˜è‡ªå‹•æŠ“å–æœ€æ–°è³‡æ–™..."

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True) 
        context = browser.new_context(viewport={'width': 1920, 'height': 1080}) 
        page = context.new_page()
        page.route("**/*.{png,jpg,jpeg,gif,svg}", lambda route: route.abort()) 

        print(f"\nğŸ¤– [çˆ¬èŸ²] ç™»å…¥ HKTVmall (é¦™æ¸¯æ™‚é–“: {now.strftime('%H:%M:%S')})")
        page.goto("https://merchant.shoalter.com/login") 
        page.locator('#account').fill(username)
        page.locator('#password').fill(password)
        page.locator('button[data-testid="ç¹¼çºŒ"]').click()
        page.wait_for_timeout(5000) 

        print(f"ğŸ¤– [çˆ¬èŸ²] æ­£åœ¨æŠ“å– ã€ä»Šæ—¥è¨‚å–®ã€‘ ({today_str})...")
        results_data["today"] = scrape_single_date(page, today_str)

        print(f"ğŸ¤– [çˆ¬èŸ²] æ­£åœ¨æŠ“å– ã€æ˜æ—¥è¨‚å–®ã€‘ ({tomorrow_str})...")
        results_data["tomorrow"] = scrape_single_date(page, tomorrow_str)

        results_data["last_updated"] = now.strftime("%Y-%m-%d %H:%M:%S")
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, ensure_ascii=False, indent=4)
            
        print(f"ğŸ‰ [çˆ¬èŸ²] æŠ“å–å®Œæˆï¼\n")
        browser.close()

def run_scraper_loop():
    load_dotenv()
    MY_USERNAME = os.getenv("HKTV_USERNAME")
    MY_PASSWORD = os.getenv("HKTV_PASSWORD")
    
    if not MY_USERNAME or not MY_PASSWORD:
        print("âŒ [ç³»çµ±åš´é‡éŒ¯èª¤] æ‰¾ä¸åˆ°å¸³è™Ÿæˆ–å¯†ç¢¼ï¼")
        return
        
    while True:
        try:
            scrape_hktvmall(MY_USERNAME, MY_PASSWORD)
        except Exception as e:
            print(f"âŒ [çˆ¬èŸ²] ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        print("â³ ä¼‘æ¯ 3 åˆ†é˜å¾Œé€²è¡Œä¸‹ä¸€è¼ªæŠ“å–...\n")
        time.sleep(180) 

# ==========================================
# 2. Streamlit ä»‹é¢èˆ‡èƒŒæ™¯åŸ·è¡Œç·’ç®¡ç†
# ==========================================

@st.cache_resource
def start_background_scraper():
    print("å•Ÿå‹•èƒŒæ™¯çˆ¬èŸ²åŸ·è¡Œç·’...")
    os.system("playwright install chromium")
    thread = threading.Thread(target=run_scraper_loop, daemon=True)
    thread.start()
    return thread

start_background_scraper()

st.set_page_config(page_title="HKTVmall è¨‚å–®ç›£æ§", layout="wide")
st.title("HKTVmall è¨‚å–®ç›£æ§é¢æ¿")

file_path = os.path.join(os.path.
