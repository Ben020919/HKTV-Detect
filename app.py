import streamlit as st
from playwright.sync_api import sync_playwright
from datetime import datetime, timedelta, time as dt_time
import threading
import json
import time
import os
import re
from dotenv import load_dotenv

# ==========================================
# 1. çˆ¬èŸ²æ©Ÿå™¨äººåŠŸèƒ½å€å¡Š
# ==========================================
def extract_total_count(text):
    if not text: return "0"
    numbers = re.findall(r'\d+', text)
    return numbers[-1] if numbers else "0"

def scrape_single_date(page, date_str):
    base_url = (
        f"https://merchant.shoalter.com/zh/order-management/orders/toship"
        f"?bu=HKTV&deliveryType=STANDARD_DELIVERY&productReadyMethod=STANDARD_DELIVERY_ALL"
        f"&searchType=ORDER_ID&storefrontCodes=H0956004%2CH0956006%2CH0956007%2CH0956008%2CH0956010%2CH0956012"
        f"&dateType=PICK_UP_DATE&startDate={date_str}&endDate={date_str}"
        f"&pageSize=20&pageNumber=1&sortColumn=orderDate&waybillStatuses="
    )
    statuses = [("CONFIRMED", "å·²å»ºç«‹"), ("ACKNOWLEDGED", "å·²ç¢ºèª"), ("PACKED", "å·²åŒ…è£"), ("PICKED", "å·²å‡ºè²¨")]
    date_data = {"date": date_str}

    page.goto(base_url + "CONFIRMED") 
    page.wait_for_timeout(2500) 
    page.locator('button:has-text("å•†æˆ¶8å°æ™‚é€è²¨")').click(force=True)
    page.wait_for_timeout(1000) 

    for status_val, status_name in statuses:
        page.locator('div.ant-select-selector:has-text("é‹å–®ç‹€æ…‹")').click(force=True)
        page.wait_for_timeout(400) 
        page.locator('button[data-testid="æ¸…é™¤å…¨éƒ¨"]').click(force=True)
        page.wait_for_timeout(300) 
        
        checkbox = page.locator(f'input[value="{status_val}"]')
        try:
            if not checkbox.is_checked(): checkbox.click(force=True)
        except Exception:
            checkbox.check(force=True)
            
        page.wait_for_timeout(200)
        page.locator('button[data-testid="å¥—ç”¨"]').click(force=True)
        page.wait_for_timeout(1500) 
        
        try:
            result_text = page.locator('span:has-text("çµæœ")').last.inner_text(timeout=3000)
            date_data[status_val] = extract_total_count(result_text)
        except Exception:
            date_data[status_val] = "0"
            
    return date_data

def scrape_hktvmall(username, password):
    now = datetime.now()
    today_str = now.strftime("%Y-%m-%d")
    tomorrow_str = (now + timedelta(days=1)).strftime("%Y-%m-%d")
    
    file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'order_data.json')
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            results_data = json.load(f)
    except Exception:
        results_data = {"today": {}, "tomorrow": {}}

    results_data["status_msg"] = "âš¡ æ©Ÿå™¨äººé‹è¡Œä¸­ï¼šæ¯ 3 åˆ†é˜è‡ªå‹•æŠ“å–æœ€æ–°è³‡æ–™..."

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True) 
        context = browser.new_context()
        page = context.new_page()
        page.route("**/*.{png,jpg,jpeg,gif,svg}", lambda route: route.abort())

        print(f"\nğŸ¤– [çˆ¬èŸ²] ç™»å…¥ HKTVmall (æ™‚é–“: {now.strftime('%H:%M:%S')})")
        page.goto("https://merchant.shoalter.com/login") 
        page.locator('#account').fill(username)
        page.locator('#password').fill(password)
        page.locator('button[data-testid="ç¹¼çºŒ"]').click()
        page.wait_for_timeout(5000) 

        print(f"ğŸ¤– [çˆ¬èŸ²] æ­£åœ¨æŠ“å– ã€ä»Šæ—¥è¨‚å–®ã€‘ ({today_str})...")
        results_data["today"] = scrape_single_date(page, today_str)

        print(f"ğŸ¤– [çˆ¬èŸ²] æ­£åœ¨æŠ“å– ã€æ˜æ—¥è¨‚å–®ã€‘ ({tomorrow_str})...")
        results_data["tomorrow"] = scrape_single_date(page, tomorrow_str)

        results_data["last_updated"] = now.strftime("%Y-%m-%d %H:%M:%S")
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, ensure_ascii=False, indent=4)
            
        print(f"ğŸ‰ [çˆ¬èŸ²] æŠ“å–å®Œæˆï¼\n")
        browser.close()

def run_scraper_loop():
    load_dotenv()
    MY_USERNAME = os.getenv("HKTV_USERNAME")
    MY_PASSWORD = os.getenv("HKTV_PASSWORD")
    
    if not MY_USERNAME or not MY_PASSWORD:
        print("âŒ [ç³»çµ±åš´é‡éŒ¯èª¤] æ‰¾ä¸åˆ°å¸³è™Ÿæˆ–å¯†ç¢¼ï¼")
        return
        
    while True:
        try:
            scrape_hktvmall(MY_USERNAME, MY_PASSWORD)
        except Exception as e:
            print(f"âŒ [çˆ¬èŸ²] ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        # ğŸ‘‰ ä¿®æ”¹ 1ï¼šæ”¹æˆ 180 ç§’ï¼ˆ3åˆ†é˜ï¼‰åŸ·è¡Œä¸€æ¬¡çˆ¬èŸ²
        print("â³ ä¼‘æ¯ 3 åˆ†é˜å¾Œé€²è¡Œä¸‹ä¸€è¼ªæŠ“å–...\n")
        time.sleep(180) 

# ==========================================
# 2. Streamlit ä»‹é¢èˆ‡èƒŒæ™¯åŸ·è¡Œç·’ç®¡ç†
# ==========================================

# ç¢ºä¿èƒŒæ™¯çˆ¬èŸ²åªå•Ÿå‹•ä¸€æ¬¡
@st.cache_resource
def start_background_scraper():
    print("å•Ÿå‹•èƒŒæ™¯çˆ¬èŸ²åŸ·è¡Œç·’...")
    thread = threading.Thread(target=run_scraper_loop, daemon=True)
    thread.start()
    return thread

# å•Ÿå‹•çˆ¬èŸ²
start_background_scraper()

# é é¢è¨­å®š
st.set_page_config(page_title="HKTVmall è¨‚å–®ç›£æ§", layout="wide")
st.title("HKTVmall è¨‚å–®ç›£æ§é¢æ¿")

# è®€å–è³‡æ–™
file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'order_data.json')
try:
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
except FileNotFoundError:
    data = {}
    st.warning("ğŸ”„ æ­£åœ¨ç­‰å¾…çˆ¬èŸ²æŠ“å–ç¬¬ä¸€ç­†è³‡æ–™ï¼Œé€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜ï¼Œè«‹ç¨å€™...")

# é¡¯ç¤ºæœ€å¾Œæ›´æ–°æ™‚é–“èˆ‡ç‹€æ…‹
last_updated = data.get("last_updated", "--")
status_msg = data.get("status_msg", "åˆå§‹åŒ–ä¸­...")

st.caption(f"ğŸ•’ ç³»çµ±æœ€å¾Œæ›´æ–°æ™‚é–“ï¼š{last_updated}")
if "ä¼‘æ¯" in status_msg:
    st.warning(status_msg)
else:
    st.success(status_msg)

st.markdown("---")

# æ¸²æŸ“ä»Šæ—¥è¨‚å–®
if "today" in data and data["today"]:
    st.subheader(f"ğŸ“¦ ä»Šæ—¥è¨‚å–® ({data['today'].get('date', '--')})")
    col1, col2, col3, col4 = st.columns(4)
    with col1: st.metric("å·²å»ºç«‹ (CONFIRMED)", data['today'].get('CONFIRMED', '--'))
    with col2: st.metric("å·²ç¢ºèª (ACKNOWLEDGED)", data['today'].get('ACKNOWLEDGED', '--'))
    with col3: st.metric("å·²åŒ…è£ (PACKED)", data['today'].get('PACKED', '--'))
    with col4: st.metric("å·²å‡ºè²¨ (PICKED)", data['today'].get('PICKED', '--'))

st.markdown("<br>", unsafe_allow_html=True)

# æ¸²æŸ“æ˜æ—¥è¨‚å–®
if "tomorrow" in data and data["tomorrow"]:
    st.subheader(f"ğŸšš æ˜æ—¥è¨‚å–® ({data['tomorrow'].get('date', '--')})")
    col1, col2, col3, col4 = st.columns(4)
    with col1: st.metric("å·²å»ºç«‹ (CONFIRMED)", data['tomorrow'].get('CONFIRMED', '--'))
    with col2: st.metric("å·²ç¢ºèª (ACKNOWLEDGED)", data['tomorrow'].get('ACKNOWLEDGED', '--'))
    with col3: st.metric("å·²åŒ…è£ (PACKED)", data['tomorrow'].get('PACKED', '--'))
    with col4: st.metric("å·²å‡ºè²¨ (PICKED)", data['tomorrow'].get('PICKED', '--'))

# ğŸ‘‰ ä¿®æ”¹ 2ï¼šæ”¹æˆ 10 ç§’æ›´æ–°ä¸€æ¬¡ç•«é¢
time.sleep(10)
st.rerun()
